{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyMCrZ06a/KKuGbZuMrLuW/7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"9VXbffbgKVZM","executionInfo":{"status":"ok","timestamp":1705335591027,"user_tz":-330,"elapsed":30090,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}},"outputId":"3131c4a9-74b2-4e5e-e39f-98a52242386a"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/gdrive/\n"]}],"source":["from google.colab import drive\n","\n","drive.mount('/content/gdrive/', force_remount=True)"]},{"cell_type":"code","source":["%cd /content/gdrive/MyDrive/Colab Notebooks/PCA-CLS"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"q1XgXlZcKcMr","executionInfo":{"status":"ok","timestamp":1705335591027,"user_tz":-330,"elapsed":6,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}},"outputId":"7376b609-23c4-4ce2-e1d9-83aae31e79ff"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS\n"]}]},{"cell_type":"code","source":["!pip install seqeval"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qMZmwKH8KeAq","executionInfo":{"status":"ok","timestamp":1705335601667,"user_tz":-330,"elapsed":10643,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}},"outputId":"fe036039-02fc-43da-e7c4-e7a19df80ecb"},"execution_count":3,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting seqeval\n","  Downloading seqeval-1.2.2.tar.gz (43 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/43.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.6/43.6 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n","Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.23.5)\n","Requirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.10/dist-packages (from seqeval) (1.2.2)\n","Requirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.11.4)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (1.3.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.21.3->seqeval) (3.2.0)\n","Building wheels for collected packages: seqeval\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-py3-none-any.whl size=16162 sha256=07195384cdf738ba606986b69aa971da65c35ab7efe563c83d9fea39d01eadfe\n","  Stored in directory: /root/.cache/pip/wheels/1a/67/4a/ad4082dd7dfc30f2abfe4d80a2ed5926a506eb8a972b4767fa\n","Successfully built seqeval\n","Installing collected packages: seqeval\n","Successfully installed seqeval-1.2.2\n"]}]},{"cell_type":"code","source":["\n","decode_file = {\n","    'status':'decode',\n","    'raw_dir':'',\n","    'dset_dir':''\n","}\n","decode_model, decoder_raw = [], []\n","\n","dataset_name = ['BC2GM', 'BC4CHEMD', 'BC5CDR-chem', 'BC5CDR-disease', 'JNLPBA', 'Linneaus', 'NCBI-disease', 's800']\n"],"metadata":{"id":"jIrwzbnZK5-S","executionInfo":{"status":"ok","timestamp":1705335601667,"user_tz":-330,"elapsed":13,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["\n","def read_conll_2003(file_path):\n","    # sentences = []\n","    actual_tags, predict_tags = [], []\n","    with open(file_path, 'r', encoding='utf-8') as file:\n","        # current_sentence = []\n","        actual_tag, predict_tag = [], []\n","        for line in file:\n","            line = line.strip()\n","            if line:\n","                # Split the line into columns\n","                columns = line.split()\n","                actual_ner = columns[1]\n","                ner_label = columns[2]\n","\n","                # Append the token information to the current sentence\n","                actual_tag.append(actual_ner)\n","                predict_tag.append(ner_label)\n","            else:\n","                # Blank line indicates the end of the current sentence\n","                if actual_tag:\n","                    actual_tags.append(actual_tag)\n","                    predict_tags.append(predict_tag)\n","\n","                    actual_tag, predict_tag = [], []\n","\n","    return actual_tags, predict_tags\n"],"metadata":{"id":"Wb33I2LkLCNV","executionInfo":{"status":"ok","timestamp":1705335601667,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["def ScoreCalculator(raw_file = 'prediction/BC2GM/raw.out', score_file='Your Classification Report Name.csv'):\n","    y_true, y_pred = read_conll_2003(raw_file)\n","    print(classification_report(y_true, y_pred, digits=4, output_dict=True))\n","\n","    clsf_report = pd.DataFrame(\n","        classification_report(y_true=y_true, y_pred=y_pred, output_dict=True)).transpose()\n","    clsf_report.to_csv(score_file, index=True)\n"],"metadata":{"id":"KXjggkm4LUIr","executionInfo":{"status":"ok","timestamp":1705335601667,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["from seqeval.metrics import accuracy_score\n","from seqeval.metrics import classification_report\n","import pandas as pd\n","import os"],"metadata":{"id":"Ij1GoXZhLEYb","executionInfo":{"status":"ok","timestamp":1705335602932,"user_tz":-330,"elapsed":1275,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["\n","def PredictionDir_builder(dir):\n","    predict_path = os.path.join('prediction', dir)\n","    try:\n","        os.mkdir(predict_path)\n","    except FileExistsError:\n","        pass\n","\n","    decode_file['raw_dir'] = os.path.join('dataset', dir, 'test.tsv')\n","    decode_file['dset_dir'] = os.path.join('model', dir, 'cnn_lstm.dset')\n","    for file in os.listdir(os.path.join('model', dir)):\n","        if file.endswith('model'):\n","            decode_model.append(os.path.join('model', dir, file))\n","            decoder_raw.append(os.path.join(predict_path, 'raw'+file+'.out'))\n","\n"],"metadata":{"id":"SMMwCDwyLFjj","executionInfo":{"status":"ok","timestamp":1705335602932,"user_tz":-330,"elapsed":3,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}}},"execution_count":8,"outputs":[]},{"cell_type":"code","source":["config_files = []\n","\n","def Config_Gen():\n","    for dir in dataset_name:\n","        PredictionDir_builder(dir)\n","        for idx,model in enumerate(decode_model):\n","            temp_file = 'decode.'+\"_\".join(model.split('/')[1:]).split('.model')[0]+'.config'\n","            # print(temp_file)\n","            with open(os.path.join('decoder', temp_file), 'w', encoding='utf-8') as file:\n","                for key, value in decode_file.items():\n","                    file.write(f\"{key}={value}\\n\")\n","                file.write(\"load_model_dir=\"+model+'\\n')\n","                file.write(\"decode_dir=\"+decoder_raw[idx])\n","\n","            config_files.append(temp_file)\n","\n"],"metadata":{"id":"hrK25-YbLLIk","executionInfo":{"status":"ok","timestamp":1705335611852,"user_tz":-330,"elapsed":4,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}}},"execution_count":9,"outputs":[]},{"cell_type":"code","source":["Config_Gen()\n","print(config_files)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6LY16NfnL65J","executionInfo":{"status":"ok","timestamp":1705335629062,"user_tz":-330,"elapsed":14890,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}},"outputId":"a85db3cb-2324-440c-8cd0-777003d3584f"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["['decode.BC2GM_cnn_lstm.0.config', 'decode.BC2GM_cnn_lstm.0.config', 'decode.BC4CHEMD_cnn_lstm.0.config', 'decode.BC2GM_cnn_lstm.0.config', 'decode.BC4CHEMD_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.1.config', 'decode.BC5CDR-chem_cnn_lstm.4.config', 'decode.BC5CDR-chem_cnn_lstm.10.config', 'decode.BC5CDR-chem_cnn_lstm.26.config', 'decode.BC2GM_cnn_lstm.0.config', 'decode.BC4CHEMD_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.1.config', 'decode.BC5CDR-chem_cnn_lstm.4.config', 'decode.BC5CDR-chem_cnn_lstm.10.config', 'decode.BC5CDR-chem_cnn_lstm.26.config', 'decode.BC5CDR-disease_cnn_lstm.0.config', 'decode.BC2GM_cnn_lstm.0.config', 'decode.BC4CHEMD_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.1.config', 'decode.BC5CDR-chem_cnn_lstm.4.config', 'decode.BC5CDR-chem_cnn_lstm.10.config', 'decode.BC5CDR-chem_cnn_lstm.26.config', 'decode.BC5CDR-disease_cnn_lstm.0.config', 'decode.JNLPBA_cnn_lstm.0.config', 'decode.JNLPBA_cnn_lstm.2.config', 'decode.JNLPBA_cnn_lstm.6.config', 'decode.JNLPBA_cnn_lstm.8.config', 'decode.BC2GM_cnn_lstm.0.config', 'decode.BC4CHEMD_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.1.config', 'decode.BC5CDR-chem_cnn_lstm.4.config', 'decode.BC5CDR-chem_cnn_lstm.10.config', 'decode.BC5CDR-chem_cnn_lstm.26.config', 'decode.BC5CDR-disease_cnn_lstm.0.config', 'decode.JNLPBA_cnn_lstm.0.config', 'decode.JNLPBA_cnn_lstm.2.config', 'decode.JNLPBA_cnn_lstm.6.config', 'decode.JNLPBA_cnn_lstm.8.config', 'decode.Linneaus_cnn_lstm.0.config', 'decode.Linneaus_cnn_lstm.1.config', 'decode.Linneaus_cnn_lstm.2.config', 'decode.Linneaus_cnn_lstm.5.config', 'decode.Linneaus_cnn_lstm.9.config', 'decode.Linneaus_cnn_lstm.20.config', 'decode.Linneaus_cnn_lstm.26.config', 'decode.BC2GM_cnn_lstm.0.config', 'decode.BC4CHEMD_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.1.config', 'decode.BC5CDR-chem_cnn_lstm.4.config', 'decode.BC5CDR-chem_cnn_lstm.10.config', 'decode.BC5CDR-chem_cnn_lstm.26.config', 'decode.BC5CDR-disease_cnn_lstm.0.config', 'decode.JNLPBA_cnn_lstm.0.config', 'decode.JNLPBA_cnn_lstm.2.config', 'decode.JNLPBA_cnn_lstm.6.config', 'decode.JNLPBA_cnn_lstm.8.config', 'decode.Linneaus_cnn_lstm.0.config', 'decode.Linneaus_cnn_lstm.1.config', 'decode.Linneaus_cnn_lstm.2.config', 'decode.Linneaus_cnn_lstm.5.config', 'decode.Linneaus_cnn_lstm.9.config', 'decode.Linneaus_cnn_lstm.20.config', 'decode.Linneaus_cnn_lstm.26.config', 'decode.NCBI-disease_cnn_lstm.0.config', 'decode.NCBI-disease_cnn_lstm.1.config', 'decode.BC2GM_cnn_lstm.0.config', 'decode.BC4CHEMD_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.0.config', 'decode.BC5CDR-chem_cnn_lstm.1.config', 'decode.BC5CDR-chem_cnn_lstm.4.config', 'decode.BC5CDR-chem_cnn_lstm.10.config', 'decode.BC5CDR-chem_cnn_lstm.26.config', 'decode.BC5CDR-disease_cnn_lstm.0.config', 'decode.JNLPBA_cnn_lstm.0.config', 'decode.JNLPBA_cnn_lstm.2.config', 'decode.JNLPBA_cnn_lstm.6.config', 'decode.JNLPBA_cnn_lstm.8.config', 'decode.Linneaus_cnn_lstm.0.config', 'decode.Linneaus_cnn_lstm.1.config', 'decode.Linneaus_cnn_lstm.2.config', 'decode.Linneaus_cnn_lstm.5.config', 'decode.Linneaus_cnn_lstm.9.config', 'decode.Linneaus_cnn_lstm.20.config', 'decode.Linneaus_cnn_lstm.26.config', 'decode.NCBI-disease_cnn_lstm.0.config', 'decode.NCBI-disease_cnn_lstm.1.config', 'decode.s800_cnn_lstm.0.config', 'decode.s800_cnn_lstm.1.config', 'decode.s800_cnn_lstm.2.config', 'decode.s800_cnn_lstm.3.config', 'decode.s800_cnn_lstm.6.config', 'decode.s800_cnn_lstm.9.config', 'decode.s800_cnn_lstm.15.config', 'decode.s800_cnn_lstm.28.config']\n"]}]},{"cell_type":"code","source":["print(decoder_raw)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"fPUntBqHPGVp","executionInfo":{"status":"ok","timestamp":1705335629062,"user_tz":-330,"elapsed":15,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}},"outputId":"61d025a5-cf49-4fe5-f2d0-4eca9aa93d5d"},"execution_count":11,"outputs":[{"output_type":"stream","name":"stdout","text":["['prediction/BC2GM/rawcnn_lstm.0.model.out', 'prediction/BC4CHEMD/rawcnn_lstm.0.model.out', 'prediction/BC5CDR-chem/rawcnn_lstm.0.model.out', 'prediction/BC5CDR-chem/rawcnn_lstm.1.model.out', 'prediction/BC5CDR-chem/rawcnn_lstm.4.model.out', 'prediction/BC5CDR-chem/rawcnn_lstm.10.model.out', 'prediction/BC5CDR-chem/rawcnn_lstm.26.model.out', 'prediction/BC5CDR-disease/rawcnn_lstm.0.model.out', 'prediction/JNLPBA/rawcnn_lstm.0.model.out', 'prediction/JNLPBA/rawcnn_lstm.2.model.out', 'prediction/JNLPBA/rawcnn_lstm.6.model.out', 'prediction/JNLPBA/rawcnn_lstm.8.model.out', 'prediction/Linneaus/rawcnn_lstm.0.model.out', 'prediction/Linneaus/rawcnn_lstm.1.model.out', 'prediction/Linneaus/rawcnn_lstm.2.model.out', 'prediction/Linneaus/rawcnn_lstm.5.model.out', 'prediction/Linneaus/rawcnn_lstm.9.model.out', 'prediction/Linneaus/rawcnn_lstm.20.model.out', 'prediction/Linneaus/rawcnn_lstm.26.model.out', 'prediction/NCBI-disease/rawcnn_lstm.0.model.out', 'prediction/NCBI-disease/rawcnn_lstm.1.model.out', 'prediction/s800/rawcnn_lstm.0.model.out', 'prediction/s800/rawcnn_lstm.1.model.out', 'prediction/s800/rawcnn_lstm.2.model.out', 'prediction/s800/rawcnn_lstm.3.model.out', 'prediction/s800/rawcnn_lstm.6.model.out', 'prediction/s800/rawcnn_lstm.9.model.out', 'prediction/s800/rawcnn_lstm.15.model.out', 'prediction/s800/rawcnn_lstm.28.model.out']\n"]}]},{"cell_type":"code","source":["\n","for configFile in config_files:\n","    cmd = '!python Bio-NER/main.py --config decoder/'+configFile\n","    print(cmd)\n","    # os.system(cmd)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7M4HRLhyLaaB","executionInfo":{"status":"ok","timestamp":1705335629062,"user_tz":-330,"elapsed":11,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}},"outputId":"fe90d3a0-8693-42e5-fbc6-ae323e09630d"},"execution_count":12,"outputs":[{"output_type":"stream","name":"stdout","text":["!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.8.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.8.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.5.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.9.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.20.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.8.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.5.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.9.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.20.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.NCBI-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.NCBI-disease_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.8.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.5.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.9.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.20.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.NCBI-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.NCBI-disease_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.3.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.9.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.15.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.28.config\n"]}]},{"cell_type":"code","source":["!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.8.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.8.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.5.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.9.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.20.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.8.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.5.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.9.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.20.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.NCBI-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.NCBI-disease_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC2GM_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC4CHEMD_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.4.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.10.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-chem_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.BC5CDR-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.JNLPBA_cnn_lstm.8.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.5.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.9.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.20.config\n","!python Bio-NER/main.py --config decoder/decode.Linneaus_cnn_lstm.26.config\n","!python Bio-NER/main.py --config decoder/decode.NCBI-disease_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.NCBI-disease_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.0.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.1.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.2.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.3.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.6.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.9.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.15.config\n","!python Bio-NER/main.py --config decoder/decode.s800_cnn_lstm.28.config"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"oTfwU2aCuUXY","executionInfo":{"status":"ok","timestamp":1705336859969,"user_tz":-330,"elapsed":1157381,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}},"outputId":"0c549a9b-88aa-481f-f8c6-98a92b6701a0"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[1;30;43mStreaming output truncated to the last 5000 lines.\u001b[0m\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-disease/cnn_lstm.0.model\n","     Decode file directory: prediction/BC5CDR-disease/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.0.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.2.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.2.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.6.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.6.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.8.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.8.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.0.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.1.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.1.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.2.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.2.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.5.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.5.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.9.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.9.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.20.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.20.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.26.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.26.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC2GM/cnn_lstm.0.model\n","     Decode file directory: prediction/BC2GM/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([79, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([35929, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC4CHEMD/cnn_lstm.0.model\n","     Decode file directory: prediction/BC4CHEMD/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([66794, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.0.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.1.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.1.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.4.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.4.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.10.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.10.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.26.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.26.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-disease/cnn_lstm.0.model\n","     Decode file directory: prediction/BC5CDR-disease/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.0.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.2.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.2.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.6.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.6.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.8.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.8.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.0.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.1.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.1.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.2.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.2.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.5.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.5.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.9.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.9.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.20.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.20.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.26.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.26.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/NCBI-disease/cnn_lstm.0.model\n","     Decode file directory: prediction/NCBI-disease/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([9819, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/NCBI-disease/cnn_lstm.1.model\n","     Decode file directory: prediction/NCBI-disease/rawcnn_lstm.1.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([9819, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC2GM/cnn_lstm.0.model\n","     Decode file directory: prediction/BC2GM/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([79, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([35929, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC4CHEMD/cnn_lstm.0.model\n","     Decode file directory: prediction/BC4CHEMD/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([66794, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.0.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.1.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.1.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.4.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.4.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.10.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.10.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-chem/cnn_lstm.26.model\n","     Decode file directory: prediction/BC5CDR-chem/rawcnn_lstm.26.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/BC5CDR-disease/cnn_lstm.0.model\n","     Decode file directory: prediction/BC5CDR-disease/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([16496, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.0.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.2.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.2.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.6.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.6.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/JNLPBA/cnn_lstm.8.model\n","     Decode file directory: prediction/JNLPBA/rawcnn_lstm.8.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([76, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([22389, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","\tsize mismatch for word_hidden.hidden2tag.weight: copying a param with shape torch.Size([14, 256]) from checkpoint, the shape in current model is torch.Size([6, 256]).\n","\tsize mismatch for word_hidden.hidden2tag.bias: copying a param with shape torch.Size([14]) from checkpoint, the shape in current model is torch.Size([6]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.0.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.1.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.1.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.2.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.2.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.5.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.5.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.9.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.9.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.20.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.20.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/Linneaus/cnn_lstm.26.model\n","     Decode file directory: prediction/Linneaus/rawcnn_lstm.26.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([87, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([24448, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/NCBI-disease/cnn_lstm.0.model\n","     Decode file directory: prediction/NCBI-disease/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([9819, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/NCBI-disease/cnn_lstm.1.model\n","     Decode file directory: prediction/NCBI-disease/rawcnn_lstm.1.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Traceback (most recent call last):\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 564, in <module>\n","    decode_results, pred_scores = load_model_decode(data, 'raw')\n","  File \"/content/gdrive/MyDrive/Colab Notebooks/PCA-CLS/Bio-NER/main.py\", line 490, in load_model_decode\n","    model.load_state_dict(torch.load(data.load_model_dir))\n","  File \"/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\", line 2152, in load_state_dict\n","    raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n","RuntimeError: Error(s) in loading state_dict for SeqLabel:\n","\tsize mismatch for word_hidden.wordrep.char_feature.char_embeddings.weight: copying a param with shape torch.Size([78, 30]) from checkpoint, the shape in current model is torch.Size([83, 30]).\n","\tsize mismatch for word_hidden.wordrep.word_embedding.weight: copying a param with shape torch.Size([9819, 300]) from checkpoint, the shape in current model is torch.Size([20190, 300]).\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/s800/cnn_lstm.0.model\n","     Decode file directory: prediction/s800/rawcnn_lstm.0.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Decode raw data, nbest: None ...\n","Right token =  159451  All token =  159699  acc =  0.9984470785665533\n","raw: time:10.82s, speed:640.27st/s; acc: 0.9984, p: 0.9912, r: 0.8973, f: 0.9419\n","Predict raw result has been written into file. prediction/s800/rawcnn_lstm.0.model.out\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/s800/cnn_lstm.1.model\n","     Decode file directory: prediction/s800/rawcnn_lstm.1.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Decode raw data, nbest: None ...\n","Right token =  159541  All token =  159699  acc =  0.9990106387641751\n","raw: time:8.86s, speed:792.86st/s; acc: 0.9990, p: 0.9795, r: 0.9459, f: 0.9624\n","Predict raw result has been written into file. prediction/s800/rawcnn_lstm.1.model.out\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/s800/cnn_lstm.2.model\n","     Decode file directory: prediction/s800/rawcnn_lstm.2.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Decode raw data, nbest: None ...\n","Right token =  159548  All token =  159699  acc =  0.9990544712239902\n","raw: time:10.11s, speed:685.66st/s; acc: 0.9991, p: 0.9825, r: 0.9479, f: 0.9649\n","Predict raw result has been written into file. prediction/s800/rawcnn_lstm.2.model.out\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/s800/cnn_lstm.3.model\n","     Decode file directory: prediction/s800/rawcnn_lstm.3.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Decode raw data, nbest: None ...\n","Right token =  159548  All token =  159699  acc =  0.9990544712239902\n","raw: time:9.33s, speed:751.98st/s; acc: 0.9991, p: 0.9865, r: 0.9454, f: 0.9656\n","Predict raw result has been written into file. prediction/s800/rawcnn_lstm.3.model.out\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/s800/cnn_lstm.6.model\n","     Decode file directory: prediction/s800/rawcnn_lstm.6.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Decode raw data, nbest: None ...\n","Right token =  159568  All token =  159699  acc =  0.9991797068234617\n","raw: time:10.06s, speed:689.26st/s; acc: 0.9992, p: 0.9922, r: 0.9499, f: 0.9706\n","Predict raw result has been written into file. prediction/s800/rawcnn_lstm.6.model.out\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/s800/cnn_lstm.9.model\n","     Decode file directory: prediction/s800/rawcnn_lstm.9.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Decode raw data, nbest: None ...\n","Right token =  159583  All token =  159699  acc =  0.9992736335230653\n","raw: time:9.12s, speed:769.94st/s; acc: 0.9993, p: 0.9918, r: 0.9544, f: 0.9727\n","Predict raw result has been written into file. prediction/s800/rawcnn_lstm.9.model.out\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/s800/cnn_lstm.15.model\n","     Decode file directory: prediction/s800/rawcnn_lstm.15.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Decode raw data, nbest: None ...\n","Right token =  159578  All token =  159699  acc =  0.9992423246231974\n","raw: time:10.24s, speed:676.85st/s; acc: 0.9992, p: 0.9943, r: 0.9529, f: 0.9732\n","Predict raw result has been written into file. prediction/s800/rawcnn_lstm.15.model.out\n","Seed num: 42\n","MODEL: decode\n","dataset/s800/test.tsv\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","DATA SUMMARY START:\n"," I/O:\n","     Start   Sequence   Laebling   task...\n","     Tag          scheme: BIO\n","     Split         token:  ||| \n","     MAX SENTENCE LENGTH: 52\n","     MAX   WORD   LENGTH: -1\n","     Number   normalized: True\n","     Word  alphabet size: 20190\n","     Char  alphabet size: 83\n","     Label alphabet size: 4\n","     Word embedding  dir: None\n","     Char embedding  dir: None\n","     Word embedding size: 300\n","     Char embedding size: 30\n","     Norm   word     emb: False\n","     Norm   char     emb: False\n","     Train  file directory: dataset/s800/train-dev.tsv\n","     Dev    file directory: dataset/s800/test.tsv\n","     Test   file directory: dataset/s800/test.tsv\n","     Raw    file directory: dataset/s800/test.tsv\n","     Dset   file directory: model/s800/cnn_lstm.dset\n","     Model  file directory: model/s800/cnn_lstm\n","     Loadmodel   directory: model/s800/cnn_lstm.28.model\n","     Decode file directory: prediction/s800/rawcnn_lstm.28.model.out\n","     Train instance number: 13580\n","     Dev   instance number: 6864\n","     Test  instance number: 6864\n","     Raw   instance number: 0\n","     FEATURE num: 0\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Model Network:\n","     Model        use_crf: False\n","     Model word extractor: LSTM\n","     Model       use_char: True\n","     Model char extractor: CNN\n","     Model char_hidden_dim: 50\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Training:\n","     Optimizer: Adam\n","     Iteration: 30\n","     BatchSize: 32\n","     Average  batch   loss: False\n"," ++++++++++++++++++++++++++++++++++++++++\n"," Hyperparameters:\n","     Hyper              lr: 0.015\n","     Hyper        lr_decay: 0.05\n","     Hyper         HP_clip: None\n","     Hyper        momentum: 0.0\n","     Hyper              l2: 1e-08\n","     Hyper      hidden_dim: 256\n","     Hyper         dropout: 0.3\n","     Hyper      lstm_layer: 2\n","     Hyper          bilstm: True\n","     Hyper             GPU: True\n","DATA SUMMARY END.\n","++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++\n","nbest: None\n","Load Model from file:  model/s800/cnn_lstm\n","build sequence labeling network...\n","use_char:  True\n","char feature extractor:  CNN\n","word feature extractor:  LSTM\n","use crf:  False\n","build word sequence feature extractor: LSTM...\n","build word representation...\n","build char sequence feature extractor: CNN ...\n","Decode raw data, nbest: None ...\n","Right token =  159582  All token =  159699  acc =  0.9992673717430917\n","raw: time:8.67s, speed:810.33st/s; acc: 0.9993, p: 0.9948, r: 0.9529, f: 0.9734\n","Predict raw result has been written into file. prediction/s800/rawcnn_lstm.28.model.out\n"]}]},{"cell_type":"code","source":["\n","for predict_file in decoder_raw:\n","    ScoreCalculator(predict_file, os.path.split(predict_file)[1])\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":355},"id":"w11HE4efLPWy","executionInfo":{"status":"error","timestamp":1705335680315,"user_tz":-330,"elapsed":517,"user":{"displayName":"Rajesh Kumar","userId":"07547447543000464212"}},"outputId":"68455e2e-3bd3-49df-e49a-437aab2582d3"},"execution_count":14,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: 'prediction/BC2GM/rawcnn_lstm.0.model.out'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-14-f72b110e1457>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mpredict_file\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdecoder_raw\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mScoreCalculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredict_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-6-e3be5a8e4585>\u001b[0m in \u001b[0;36mScoreCalculator\u001b[0;34m(raw_file, score_file)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mScoreCalculator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'prediction/BC2GM/raw.out'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'Your Classification Report Name.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread_conll_2003\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclassification_report\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdigits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     clsf_report = pd.DataFrame(\n","\u001b[0;32m<ipython-input-5-fae0abdeb056>\u001b[0m in \u001b[0;36mread_conll_2003\u001b[0;34m(file_path)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# sentences = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mactual_tags\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_tags\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m         \u001b[0;31m# current_sentence = []\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0mactual_tag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_tag\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'prediction/BC2GM/rawcnn_lstm.0.model.out'"]}]},{"cell_type":"code","source":[],"metadata":{"id":"DkwoHtHCXQla"},"execution_count":null,"outputs":[]}]}